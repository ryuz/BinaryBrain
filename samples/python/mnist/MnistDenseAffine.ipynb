{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BinaryBrain による一般的な多層パーセプトロン\n",
    "\n",
    "BinaryBrainを使って、一般的な多層パーセプトロンを構成してMNISTを試します。\n",
    "これはBinaryBrainのFPGA化対象外のネットなので計算しておしまいです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import binarybrain as bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの準備には PyTorch の torchvision を流用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "net_name        = 'MnistMlp'\n",
    "data_path       = os.path.join('./data/', net_name)\n",
    "epochs          = 4\n",
    "mini_batch_size = 64\n",
    "\n",
    "# dataset\n",
    "dataset_path = './data/'\n",
    "dataset_train = torchvision.datasets.MNIST(root=dataset_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataset_test  = torchvision.datasets.MNIST(root=dataset_path, train=False, transform=transforms.ToTensor(), download=True)\n",
    "loader_train = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=mini_batch_size, shuffle=True, num_workers=2)\n",
    "loader_test  = torch.utils.data.DataLoader(dataset=dataset_test,  batch_size=mini_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークを定義します。\n",
    "最後の層は Loss関数側で LossSoftmaxCrossEntropy を使うので活性化層を付けません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ネット定義\n",
    "net = bb.Sequential([\n",
    "            bb.DenseAffine([1024]),\n",
    "            bb.ReLU(),\n",
    "            bb.DenseAffine([512]),\n",
    "            bb.ReLU(),\n",
    "            bb.DenseAffine([10]),\n",
    "        ])\n",
    "net.set_input_shape([28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数/評価関数/最適化器を作ります。\n",
    "最適化器にはネットワークの重みパラメータと勾配を紐づけます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数/評価関数/最適化\n",
    "loss      = bb.LossSoftmaxCrossEntropy()\n",
    "metrics   = bb.MetricsCategoricalAccuracy()\n",
    "optimizer = bb.OptimizerAdam()\n",
    "\n",
    "optimizer.set_variables(net.get_parameters(), net.get_gradients())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際の学習を行います。\n",
    "エポックごとにテストデータセットで評価も行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0] : loss=0.164124 accuracy=0.975200\n",
      "epoch[1] : loss=0.119439 accuracy=0.973250\n",
      "epoch[2] : loss=0.097397 accuracy=0.972300\n",
      "epoch[3] : loss=0.083052 accuracy=0.974175\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 学習\n",
    "    for images, labels in loader_train:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "        y_buf = net.forward(x_buf, train=True)\n",
    "        dy_buf = loss.calculate(y_buf, t_buf)\n",
    "        net.backward(dy_buf)\n",
    "        optimizer.update()\n",
    "\n",
    "    # 評価\n",
    "    for images, labels in loader_test:\n",
    "        x_buf = bb.FrameBuffer.from_numpy(np.array(images).astype(np.float32))\n",
    "        t_buf = bb.FrameBuffer.from_numpy(np.identity(10)[np.array(labels)].astype(np.float32))\n",
    "        y_buf = net.forward(x_buf, train=False)\n",
    "        loss.calculate(y_buf, t_buf)\n",
    "        metrics.calculate(y_buf, t_buf)\n",
    "\n",
    "    print('epoch[%d] : loss=%f accuracy=%f' % (epoch, loss.get(), metrics.get()))\n",
    "    \n",
    "    bb.save_networks(data_path, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
